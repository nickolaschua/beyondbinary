{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": "# Cell 1: Upload and extract MP_Data.zip directly\nimport os, zipfile\nfrom google.colab import files\n\nprint('Select your MP_Data.zip file...')\nuploaded = files.upload()\n\nzip_name = list(uploaded.keys())[0]\nassert zip_name.endswith('.zip'), f'Expected a .zip file, got: {zip_name}'\n\nprint(f'\\nUploaded: {zip_name} ({len(uploaded[zip_name]) / (1024*1024):.1f} MB)')\n\nwith zipfile.ZipFile(zip_name, 'r') as z:\n    z.extractall('/content/')\n\nDATA_PATH = '/content/MP_Data'\nMODELS_DIR = '/content/models'\nos.makedirs(MODELS_DIR, exist_ok=True)\n\nprint(f'\\nDATA_PATH: {DATA_PATH}')\nprint(f'Data exists: {os.path.isdir(DATA_PATH)}')\nprint(f'Signs found: {sorted(os.listdir(DATA_PATH))}')",
   "metadata": {
    "id": "cell-1-mount-drive",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 2: Imports\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)",
   "metadata": {
    "id": "cell-2-imports"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 3: Configuration\n# DATA_PATH set in Cell 1\nACTIONS = np.array([\n    'Hello', 'Thank_You', 'Help', 'Yes', 'No',\n    'Please', 'Sorry', 'I_Love_You', 'Stop', 'More'\n])\nNUM_SEQUENCES = 30\nSEQUENCE_LENGTH = 30\nlabel_map = {label: num for num, label in enumerate(ACTIONS)}\n\nprint(f'Actions ({len(ACTIONS)}): {list(ACTIONS)}')\nprint(f'Sequences per action: {NUM_SEQUENCES}')\nprint(f'Frames per sequence: {SEQUENCE_LENGTH}')\nprint(f'Expected total sequences: {len(ACTIONS) * NUM_SEQUENCES}')",
   "metadata": {
    "id": "cell-3-config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 4: Load and Prepare Data (auto-discovers all sequences)\nsequences = []\nlabels = []\nskipped = 0\n\nfor action in ACTIONS:\n    action_dir = os.path.join(DATA_PATH, action)\n    if not os.path.isdir(action_dir):\n        print(f'WARNING: {action_dir} not found!')\n        continue\n\n    # Auto-discover all sequence directories\n    seq_dirs = sorted([d for d in os.listdir(action_dir)\n                       if os.path.isdir(os.path.join(action_dir, d)) and d.isdigit()],\n                      key=int)\n\n    for seq_name in seq_dirs:\n        window = []\n        valid = True\n        for frame_idx in range(SEQUENCE_LENGTH):\n            frame_path = os.path.join(action_dir, seq_name, f'{frame_idx}.npy')\n            if not os.path.isfile(frame_path):\n                valid = False\n                break\n            try:\n                frame = np.load(frame_path)\n                if frame.shape != (1662,):\n                    print(f'Warning: unexpected shape {frame.shape} in {frame_path}')\n                    valid = False\n                    break\n                window.append(frame)\n            except Exception as e:\n                print(f'Error loading {frame_path}: {e}')\n                valid = False\n                break\n\n        if valid and len(window) == SEQUENCE_LENGTH:\n            sequences.append(window)\n            labels.append(label_map[action])\n        else:\n            skipped += 1\n\nX = np.array(sequences)\ny = to_categorical(np.array(labels), num_classes=len(ACTIONS))\n\nprint(f'X shape: {X.shape}')\nprint(f'y shape: {y.shape}')\nprint(f'Skipped sequences: {skipped}')\n\n# Per-class counts\ny_int = np.argmax(y, axis=1)\nfor i, action in enumerate(ACTIONS):\n    print(f'  {action}: {np.sum(y_int == i)} sequences')",
   "metadata": {
    "id": "cell-4-load-data"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 5: Train/Test Split (90/10 with stratification)\n",
    "y_integers = np.argmax(y, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y_integers\n",
    ")\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]}')\n",
    "print(f'Test samples:     {X_test.shape[0]}')\n",
    "print(f'Train shape: {X_train.shape}')\n",
    "print(f'Test shape:  {X_test.shape}')"
   ],
   "metadata": {
    "id": "cell-5-split"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 5b: Data Augmentation (boosts accuracy significantly with limited webcam data)\n#\n# With only 30 sequences per sign, the model doesn't see enough variation.\n# Augmentation creates synthetic training data with:\n#   - Gaussian noise (simulates tracking jitter)\n#   - Temporal shifts (simulates timing variation)\n#   - Speed variation (simulates faster/slower signing)\n#   - Frame dropout (builds robustness)\n#   - L/R hand mirroring (doubles effective data)\n#\n# Set AUGMENT_MULTIPLIER=0 to disable and train on raw data only.\n\nAUGMENT_MULTIPLIER = 5   # Number of augmented copies per sample\nUSE_MIRROR = True        # Swap L/R hands for additional variation\n\n# --- Augmentation functions (self-contained for Colab) ---\n\n# Keypoint index ranges\nLH_START, LH_END = 1536, 1599\nRH_START, RH_END = 1599, 1662\n\ndef add_gaussian_noise(seq, std=0.005, rng=None):\n    rng = rng or np.random.default_rng()\n    aug = seq.copy()\n    noise = rng.normal(0, std, size=aug.shape).astype(aug.dtype)\n    mask = aug != 0\n    aug[mask] += noise[mask]\n    return aug\n\ndef temporal_shift(seq, max_shift=3, rng=None):\n    rng = rng or np.random.default_rng()\n    shift = rng.integers(-max_shift, max_shift + 1)\n    if shift == 0: return seq.copy()\n    aug = np.zeros_like(seq)\n    sl = len(seq)\n    if shift > 0:\n        aug[:shift] = seq[0]; aug[shift:] = seq[:sl - shift]\n    else:\n        a = abs(shift); aug[:sl - a] = seq[a:]; aug[sl - a:] = seq[-1]\n    return aug\n\ndef mirror_hands(seq):\n    aug = seq.copy()\n    lh, rh = aug[:, LH_START:LH_END].copy(), aug[:, RH_START:RH_END].copy()\n    aug[:, LH_START:LH_END] = rh; aug[:, RH_START:RH_END] = lh\n    return aug\n\ndef speed_variation(seq, factor_range=(0.85, 1.15), rng=None):\n    rng = rng or np.random.default_rng()\n    sl = len(seq); factor = rng.uniform(*factor_range)\n    new_len = max(int(sl * factor), 2)\n    orig_idx = np.linspace(0, sl - 1, new_len)\n    tgt_idx = np.linspace(0, new_len - 1, sl)\n    mapped = np.interp(tgt_idx, np.arange(new_len), orig_idx)\n    aug = np.zeros_like(seq)\n    for i in range(seq.shape[1]):\n        aug[:, i] = np.interp(mapped, np.arange(sl), seq[:, i])\n    return aug\n\ndef frame_dropout(seq, drop_rate=0.1, rng=None):\n    rng = rng or np.random.default_rng()\n    aug = seq.copy()\n    for i in range(1, len(aug) - 1):\n        if rng.random() < drop_rate: aug[i] = aug[i - 1]\n    return aug\n\ndef augment_sequence(seq, rng=None):\n    rng = rng or np.random.default_rng()\n    aug = seq.copy()\n    if rng.random() < 0.8: aug = add_gaussian_noise(aug, std=rng.uniform(0.002, 0.008), rng=rng)\n    if rng.random() < 0.5: aug = temporal_shift(aug, max_shift=3, rng=rng)\n    if rng.random() < 0.4: aug = speed_variation(aug, rng=rng)\n    if rng.random() < 0.3: aug = frame_dropout(aug, drop_rate=0.1, rng=rng)\n    return aug\n\n# --- Apply augmentation ---\nif AUGMENT_MULTIPLIER > 0:\n    rng = np.random.default_rng(42)\n    original_count = len(X_train)\n    all_X, all_y = [X_train], [y_train]\n\n    for i in range(AUGMENT_MULTIPLIER):\n        batch = np.array([augment_sequence(s, rng=rng) for s in X_train])\n        all_X.append(batch); all_y.append(y_train)\n\n    if USE_MIRROR:\n        combined_X = np.concatenate(all_X, axis=0)\n        combined_y = np.concatenate(all_y, axis=0)\n        mirrored = np.array([mirror_hands(s) for s in combined_X])\n        all_X = [combined_X, mirrored]; all_y = [combined_y, combined_y]\n\n    X_train = np.concatenate(all_X, axis=0)\n    y_train = np.concatenate(all_y, axis=0)\n\n    # Shuffle\n    idx = rng.permutation(len(X_train))\n    X_train, y_train = X_train[idx], y_train[idx]\n\n    print(f'Augmented: {original_count} -> {len(X_train)} training samples ({len(X_train)/original_count:.1f}x)')\nelse:\n    print('Augmentation disabled (AUGMENT_MULTIPLIER=0)')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 6: Build LSTM Model\n# CRITICAL: Do not change this architecture\n# - LSTM activation MUST be 'tanh' (not relu)\n# - BatchNormalization after each LSTM layer\n# - Dropout(0.2) for regularization\n\nmodel = Sequential([\n    LSTM(64, return_sequences=True, activation='tanh', input_shape=(30, 1662)),\n    BatchNormalization(),\n    Dropout(0.2),\n\n    LSTM(128, return_sequences=True, activation='tanh'),\n    BatchNormalization(),\n    Dropout(0.2),\n\n    LSTM(64, return_sequences=False, activation='tanh'),\n    BatchNormalization(),\n    Dropout(0.2),\n\n    Dense(64, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(len(ACTIONS), activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['categorical_accuracy']\n)\nmodel.summary()",
   "metadata": {
    "id": "cell-6-model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 7: Train\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_categorical_accuracy',\n",
    "    patience=30,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_categorical_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "tb_callback = TensorBoard(log_dir='./logs')\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stop, checkpoint, tb_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f'\\nBest validation accuracy: {max(history.history[\"val_categorical_accuracy\"]):.4f}')"
   ],
   "metadata": {
    "id": "cell-7-train"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 8: Evaluate on TEST set\nfrom tensorflow.keras.models import load_model\n\n# Load the best model from checkpoint\nbest_model = load_model('best_model.h5')\n\n# Evaluate on X_test (NOT X_train)\ntest_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\nprint(f'Test Loss:     {test_loss:.4f}')\nprint(f'Test Accuracy: {test_acc:.4f}')\n\n# Classification report\ny_pred = best_model.predict(X_test, verbose=0)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true_classes = np.argmax(y_test, axis=1)\n\nprint('\\nClassification Report:')\nprint(classification_report(\n    y_true_classes,\n    y_pred_classes,\n    target_names=ACTIONS.tolist(),\n    zero_division=0\n))\n\n# Confusion matrix heatmap\ncm = confusion_matrix(y_true_classes, y_pred_classes)\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=ACTIONS, yticklabels=ACTIONS)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=150)\nplt.show()\nprint('Confusion matrix saved to confusion_matrix.png')",
   "metadata": {
    "id": "cell-8-evaluate"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 9: Training History Plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history.history['categorical_accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history.history['val_categorical_accuracy'], label='Val Accuracy')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history.history['loss'], label='Train Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()\n",
    "print('Training history saved to training_history.png')"
   ],
   "metadata": {
    "id": "cell-9-history"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 10: Save + Download model\nMODEL_PATH = os.path.join(MODELS_DIR, 'action_model.h5')\n\nbest_model.save(MODEL_PATH)\nnp.save('actions.npy', ACTIONS)\n\n# Download directly to your PC\nfrom google.colab import files\nfiles.download(MODEL_PATH)\nfiles.download('actions.npy')\nfiles.download('confusion_matrix.png')\nprint('Downloads started â€” place action_model.h5 in ml/models/ locally')",
   "metadata": {
    "id": "cell-10-save"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}