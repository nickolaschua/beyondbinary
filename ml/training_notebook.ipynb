{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": "# Cell 1: Upload preprocessed training data\n# Run `python ml/preprocess_for_colab.py` locally first to create training_data.npz\n# This is ~15-20 MB instead of hundreds of MB for the raw zip.\nimport os\nimport numpy as np\nfrom google.colab import files\n\nprint('Select your training_data.npz file...')\nuploaded = files.upload()\n\nfile_name = list(uploaded.keys())[0]\nassert file_name.endswith('.npz'), f'Expected .npz file, got: {file_name}'\nprint(f'Uploaded: {file_name} ({len(uploaded[file_name]) / (1024*1024):.1f} MB)')\n\ndata = np.load(file_name)\nX = data['X']\ny_raw = data['y']\nACTIONS = data['actions']\n\nSEQUENCE_LENGTH = X.shape[1]\nNUM_FEATURES = X.shape[2]\n\nMODELS_DIR = '/content/models'\nos.makedirs(MODELS_DIR, exist_ok=True)\n\nprint(f'\\nX shape: {X.shape}')\nprint(f'Actions ({len(ACTIONS)}): {list(ACTIONS)}')\nprint(f'Sequences per action:')\nfor i, action in enumerate(ACTIONS):\n    print(f'  {action}: {np.sum(y_raw == i)}')",
   "metadata": {
    "id": "cell-1-mount-drive"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 2: Imports\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)",
   "metadata": {
    "id": "cell-2-imports"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 3: Configuration\nlabel_map = {label: num for num, label in enumerate(ACTIONS)}\n\n# Dataset layout:\n#   Per class: 90 sequences (Person A: 0-29, Person B: 30-89)\n#   Demo target: Person B\nSEQS_PER_CLASS = int(np.sum(y_raw == 0))\nPERSON_A = (0, 30)    # sequences 0-29\nPERSON_B = (30, SEQS_PER_CLASS)  # sequences 30-89\n\nprint(f'Actions ({len(ACTIONS)}): {list(ACTIONS)}')\nprint(f'Frames per sequence: {SEQUENCE_LENGTH}')\nprint(f'Features per frame: {NUM_FEATURES} (face landmarks stripped)')\nprint(f'Total sequences: {len(X)}')\nprint(f'Sequences per class: {SEQS_PER_CLASS}')\nprint(f'Person A: seqs {PERSON_A[0]}-{PERSON_A[1]-1}, Person B: seqs {PERSON_B[0]}-{PERSON_B[1]-1}')",
   "metadata": {
    "id": "cell-3-config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 4: Prepare labels\ny = to_categorical(y_raw, num_classes=len(ACTIONS))\n\nprint(f'X shape: {X.shape}')\nprint(f'y shape: {y.shape}')\nprint(f'Data already face-stripped and normalized by preprocess_for_colab.py')",
   "metadata": {
    "id": "cell-4-load-data"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 5: Person-aware Train/Val/Test Split\n#\n# CHANGE: Replaced random train_test_split with person-aware split.\n# This prevents data leakage from near-duplicate sequences (recorded\n# back-to-back by the same person) ending up in both train and test.\n#\n# Layout per class (90 sequences):\n#   Train: Person A (0-29) + Person B early (30-71) = 72 sequences\n#   Val:   Person B (72-80) = 9 sequences\n#   Test:  Person B (81-89) = 9 sequences\n#\n# Val/Test are Person B only since the demo targets Person B.\n\nX_train_list, y_train_list = [], []\nX_val_list, y_val_list = [], []\nX_test_list, y_test_list = [], []\n\nfor i, action in enumerate(ACTIONS):\n    mask = y_raw == i\n    class_data = X[mask]  # (90, 30, 258)\n\n    # Train: Person A (0-29) + Person B early (30-71)\n    train_data = np.concatenate([class_data[0:30], class_data[30:72]])\n    # Val: Person B (72-80)\n    val_data = class_data[72:81]\n    # Test: Person B (81-89)\n    test_data = class_data[81:90]\n\n    X_train_list.append(train_data)\n    X_val_list.append(val_data)\n    X_test_list.append(test_data)\n    y_train_list.extend([i] * len(train_data))\n    y_val_list.extend([i] * len(val_data))\n    y_test_list.extend([i] * len(test_data))\n\nX_train = np.concatenate(X_train_list)\nX_val = np.concatenate(X_val_list)\nX_test = np.concatenate(X_test_list)\ny_train = to_categorical(np.array(y_train_list), num_classes=len(ACTIONS))\ny_val = to_categorical(np.array(y_val_list), num_classes=len(ACTIONS))\ny_test = to_categorical(np.array(y_test_list), num_classes=len(ACTIONS))\n\n# Shuffle training data\nrng = np.random.default_rng(42)\nidx = rng.permutation(len(X_train))\nX_train, y_train = X_train[idx], y_train[idx]\n\nprint(f'Training samples:   {X_train.shape[0]} (Person A + Person B seqs 30-71)')\nprint(f'Validation samples: {X_val.shape[0]} (Person B seqs 72-80)')\nprint(f'Test samples:       {X_test.shape[0]} (Person B seqs 81-89)')\nprint(f'\\nPer-class split:')\nfor i, action in enumerate(ACTIONS):\n    tr = np.sum(np.argmax(y_train, axis=1) == i)\n    va = np.sum(np.argmax(y_val, axis=1) == i)\n    te = np.sum(np.argmax(y_test, axis=1) == i)\n    print(f'  {action:15s}  train={tr}  val={va}  test={te}')",
   "metadata": {
    "id": "cell-5-split"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 5b: Data Augmentation (on 258-feature preprocessed data)\n#\n# CHANGES:\n#   - AUGMENT_MULTIPLIER: 5 -> 7 (more diversity with mirror off)\n#   - USE_MIRROR: False (ASL signs are dominant-hand specific)\n\nAUGMENT_MULTIPLIER = 7\nUSE_MIRROR = False  # Disabled: ASL signs are hand-specific\n\n# Hand indices in 258-feature space: [pose(0:132), lh(132:195), rh(195:258)]\nLH_START, LH_END = 132, 195\nRH_START, RH_END = 195, 258\n\ndef add_gaussian_noise(seq, std=0.005, rng=None):\n    rng = rng or np.random.default_rng()\n    aug = seq.copy()\n    noise = rng.normal(0, std, size=aug.shape).astype(aug.dtype)\n    mask = aug != 0\n    aug[mask] += noise[mask]\n    return aug\n\ndef temporal_shift(seq, max_shift=3, rng=None):\n    rng = rng or np.random.default_rng()\n    shift = rng.integers(-max_shift, max_shift + 1)\n    if shift == 0: return seq.copy()\n    aug = np.zeros_like(seq)\n    sl = len(seq)\n    if shift > 0:\n        aug[:shift] = seq[0]; aug[shift:] = seq[:sl - shift]\n    else:\n        a = abs(shift); aug[:sl - a] = seq[a:]; aug[sl - a:] = seq[-1]\n    return aug\n\ndef mirror_hands(seq):\n    aug = seq.copy()\n    lh, rh = aug[:, LH_START:LH_END].copy(), aug[:, RH_START:RH_END].copy()\n    aug[:, LH_START:LH_END] = rh; aug[:, RH_START:RH_END] = lh\n    return aug\n\ndef speed_variation(seq, factor_range=(0.85, 1.15), rng=None):\n    rng = rng or np.random.default_rng()\n    sl = len(seq); factor = rng.uniform(*factor_range)\n    new_len = max(int(sl * factor), 2)\n    orig_idx = np.linspace(0, sl - 1, new_len)\n    tgt_idx = np.linspace(0, new_len - 1, sl)\n    mapped = np.interp(tgt_idx, np.arange(new_len), orig_idx)\n    aug = np.zeros_like(seq)\n    for i in range(seq.shape[1]):\n        aug[:, i] = np.interp(mapped, np.arange(sl), seq[:, i])\n    return aug\n\ndef frame_dropout(seq, drop_rate=0.1, rng=None):\n    rng = rng or np.random.default_rng()\n    aug = seq.copy()\n    for i in range(1, len(aug) - 1):\n        if rng.random() < drop_rate: aug[i] = aug[i - 1]\n    return aug\n\ndef augment_sequence(seq, rng=None):\n    rng = rng or np.random.default_rng()\n    aug = seq.copy()\n    if rng.random() < 0.8: aug = add_gaussian_noise(aug, std=rng.uniform(0.002, 0.008), rng=rng)\n    if rng.random() < 0.5: aug = temporal_shift(aug, max_shift=3, rng=rng)\n    if rng.random() < 0.4: aug = speed_variation(aug, rng=rng)\n    if rng.random() < 0.3: aug = frame_dropout(aug, drop_rate=0.1, rng=rng)\n    return aug\n\n# --- Apply augmentation ---\nif AUGMENT_MULTIPLIER > 0:\n    rng = np.random.default_rng(42)\n    original_count = len(X_train)\n    all_X, all_y = [X_train], [y_train]\n\n    for i in range(AUGMENT_MULTIPLIER):\n        batch = np.array([augment_sequence(s, rng=rng) for s in X_train])\n        all_X.append(batch); all_y.append(y_train)\n\n    X_train = np.concatenate(all_X, axis=0)\n    y_train = np.concatenate(all_y, axis=0)\n\n    idx = rng.permutation(len(X_train))\n    X_train, y_train = X_train[idx], y_train[idx]\n\n    print(f'Augmented: {original_count} -> {len(X_train)} training samples ({len(X_train)/original_count:.1f}x)')\nelse:\n    print('Augmentation disabled (AUGMENT_MULTIPLIER=0)')",
   "metadata": {
    "id": "cell-5b-augment"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 6: Build Bidirectional LSTM Model\n#\n# CHANGES:\n#   - l2 regularization: 1e-4 -> 5e-4 (stronger regularization)\n#   - First dropout: 0.5 -> 0.6 (reduce overfitting)\n#   - Loss: categorical_crossentropy -> with label_smoothing=0.1\n\nreg = l2(5e-4)\n\nmodel = Sequential([\n    Bidirectional(LSTM(64, activation='tanh',\n                       kernel_regularizer=reg, recurrent_regularizer=reg),\n                  input_shape=(SEQUENCE_LENGTH, NUM_FEATURES)),\n    BatchNormalization(),\n    Dropout(0.6),\n\n    Dense(32, activation='relu', kernel_regularizer=reg),\n    Dropout(0.4),\n    Dense(len(ACTIONS), activation='softmax')\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n    metrics=['categorical_accuracy']\n)\nmodel.summary()",
   "metadata": {
    "id": "cell-6-model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 7: Train\n#\n# CHANGES:\n#   - batch_size: 16 -> 64 (smoother gradients, reduces val loss spikes)\n#   - Added ReduceLROnPlateau (halves LR when val_loss plateaus)\n\nearly_stop = EarlyStopping(\n    monitor='val_categorical_accuracy',\n    patience=50,\n    restore_best_weights=True,\n    verbose=1\n)\ncheckpoint = ModelCheckpoint(\n    'best_model.h5',\n    monitor='val_categorical_accuracy',\n    save_best_only=True,\n    verbose=1\n)\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=10,\n    min_lr=1e-6,\n    verbose=1\n)\ntb_callback = TensorBoard(log_dir='./logs')\n\nhistory = model.fit(\n    X_train, y_train,\n    epochs=500,\n    batch_size=64,\n    validation_data=(X_val, y_val),\n    callbacks=[early_stop, checkpoint, reduce_lr, tb_callback],\n    verbose=1\n)\n\nprint(f'\\nBest validation accuracy: {max(history.history[\"val_categorical_accuracy\"]):.4f}')\nprint(f'Best validation loss: {min(history.history[\"val_loss\"]):.4f}')",
   "metadata": {
    "id": "cell-7-train"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 8: Evaluate on TEST set\nfrom tensorflow.keras.models import load_model\n\nbest_model = load_model('best_model.h5')\n\ntest_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\nprint(f'Test Loss:     {test_loss:.4f}')\nprint(f'Test Accuracy: {test_acc:.4f}')\n\ny_pred = best_model.predict(X_test, verbose=0)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true_classes = np.argmax(y_test, axis=1)\n\nprint('\\nClassification Report:')\nprint(classification_report(\n    y_true_classes,\n    y_pred_classes,\n    target_names=ACTIONS.tolist(),\n    zero_division=0\n))\n\n# Confusion matrix heatmap\ncm = confusion_matrix(y_true_classes, y_pred_classes)\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=ACTIONS, yticklabels=ACTIONS)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix (Person B held-out test set)')\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=150)\nplt.show()\nprint('Confusion matrix saved to confusion_matrix.png')",
   "metadata": {
    "id": "cell-8-evaluate"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 9: Training History Plots\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].plot(history.history['categorical_accuracy'], label='Train Accuracy')\naxes[0].plot(history.history['val_categorical_accuracy'], label='Val Accuracy')\naxes[0].set_title('Model Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Accuracy')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\naxes[1].plot(history.history['loss'], label='Train Loss')\naxes[1].plot(history.history['val_loss'], label='Val Loss')\naxes[1].set_title('Model Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Loss')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('training_history.png', dpi=150)\nplt.show()\nprint('Training history saved to training_history.png')",
   "metadata": {
    "id": "cell-9-history"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 10: Save + Convert to TFLite + Download\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\n\nMODEL_PATH = os.path.join(MODELS_DIR, 'action_model.keras')\nbest_model.save(MODEL_PATH)\nnp.save('actions.npy', ACTIONS)\n\n# Clone model onto CPU to avoid CuDNN ops that TFLite can't handle\nwith tf.device('/cpu:0'):\n    cpu_model = tf.keras.models.clone_model(best_model)\n    cpu_model.set_weights(best_model.get_weights())\n\nconverter = tf.lite.TFLiteConverter.from_keras_model(cpu_model)\nconverter.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS,\n    tf.lite.OpsSet.SELECT_TF_OPS,\n]\nconverter._experimental_lower_tensor_list_ops = False\ntflite_model = converter.convert()\n\ntflite_path = os.path.join(MODELS_DIR, 'action_model.tflite')\nwith open(tflite_path, 'wb') as f:\n    f.write(tflite_model)\nprint(f'TFLite model saved: {len(tflite_model)/1024:.1f} KB')\n\n# Download to your PC\nfrom google.colab import files\nfiles.download(MODEL_PATH)\nfiles.download(tflite_path)\nfiles.download('actions.npy')\nfiles.download('confusion_matrix.png')\nprint('Downloads started - place action_model.tflite and actions.npy in ml/models/ locally')",
   "metadata": {
    "id": "cell-10-save"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
