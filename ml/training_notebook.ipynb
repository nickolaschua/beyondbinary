{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": "# Cell 1: Upload preprocessed training data\n# Run `python ml/preprocess_for_colab.py` locally first to create training_data.npz\n# This is ~15-20 MB instead of hundreds of MB for the raw zip.\nimport os\nimport numpy as np\nfrom google.colab import files\n\nprint('Select your training_data.npz file...')\nuploaded = files.upload()\n\nfile_name = list(uploaded.keys())[0]\nassert file_name.endswith('.npz'), f'Expected .npz file, got: {file_name}'\nprint(f'Uploaded: {file_name} ({len(uploaded[file_name]) / (1024*1024):.1f} MB)')\n\ndata = np.load(file_name)\nX = data['X']\ny_raw = data['y']\nACTIONS = data['actions']\n\nSEQUENCE_LENGTH = X.shape[1]\nNUM_FEATURES = X.shape[2]\n\nMODELS_DIR = '/content/models'\nos.makedirs(MODELS_DIR, exist_ok=True)\n\nprint(f'\\nX shape: {X.shape}')\nprint(f'Actions ({len(ACTIONS)}): {list(ACTIONS)}')\nprint(f'Sequences per action:')\nfor i, action in enumerate(ACTIONS):\n    print(f'  {action}: {np.sum(y_raw == i)}')",
   "metadata": {
    "id": "cell-1-mount-drive",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 2: Imports\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)",
   "metadata": {
    "id": "cell-2-imports"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 3: Configuration\n# ACTIONS, SEQUENCE_LENGTH, NUM_FEATURES loaded from .npz in Cell 1\nlabel_map = {label: num for num, label in enumerate(ACTIONS)}\n\nprint(f'Actions ({len(ACTIONS)}): {list(ACTIONS)}')\nprint(f'Frames per sequence: {SEQUENCE_LENGTH}')\nprint(f'Features per frame: {NUM_FEATURES} (face landmarks stripped)')\nprint(f'Total sequences: {len(X)}')",
   "metadata": {
    "id": "cell-3-config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 4: Prepare labels (data already preprocessed by local script)\nfrom tensorflow.keras.utils import to_categorical\n\ny = to_categorical(y_raw, num_classes=len(ACTIONS))\n\nprint(f'X shape: {X.shape}')\nprint(f'y shape: {y.shape}')\nprint(f'Data already face-stripped and normalized by preprocess_for_colab.py')",
   "metadata": {
    "id": "cell-4-load-data"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 5: Train/Val/Test Split (before augmentation to prevent leakage)\ny_integers = np.argmax(y, axis=1)\n\n# First split off the test set (10%)\nX_trainval, X_test, y_trainval, y_test = train_test_split(\n    X, y, test_size=0.1, random_state=42, stratify=y_integers\n)\n\n# Then split train/val (15% of trainval = ~13.5% of total)\ny_trainval_int = np.argmax(y_trainval, axis=1)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_trainval, y_trainval, test_size=0.15, random_state=42, stratify=y_trainval_int\n)\n\nprint(f'Training samples:   {X_train.shape[0]}')\nprint(f'Validation samples: {X_val.shape[0]}')\nprint(f'Test samples:       {X_test.shape[0]}')\nprint(f'(Augmentation will only touch training set)')",
   "metadata": {
    "id": "cell-5-split"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 5b: Data Augmentation (on 258-feature preprocessed data)\n#\n# Augmentation creates synthetic training data with:\n#   - Gaussian noise (simulates tracking jitter)\n#   - Temporal shifts (simulates timing variation)\n#   - Speed variation (simulates faster/slower signing)\n#   - Frame dropout (builds robustness)\n#\n# Mirror is DISABLED — many ASL signs are dominant-hand specific.\n\nAUGMENT_MULTIPLIER = 5\nUSE_MIRROR = False  # Disabled: ASL signs are hand-specific\n\n# Hand indices in 258-feature space: [pose(0:132), lh(132:195), rh(195:258)]\nLH_START, LH_END = 132, 195\nRH_START, RH_END = 195, 258\n\ndef add_gaussian_noise(seq, std=0.005, rng=None):\n    rng = rng or np.random.default_rng()\n    aug = seq.copy()\n    noise = rng.normal(0, std, size=aug.shape).astype(aug.dtype)\n    mask = aug != 0\n    aug[mask] += noise[mask]\n    return aug\n\ndef temporal_shift(seq, max_shift=3, rng=None):\n    rng = rng or np.random.default_rng()\n    shift = rng.integers(-max_shift, max_shift + 1)\n    if shift == 0: return seq.copy()\n    aug = np.zeros_like(seq)\n    sl = len(seq)\n    if shift > 0:\n        aug[:shift] = seq[0]; aug[shift:] = seq[:sl - shift]\n    else:\n        a = abs(shift); aug[:sl - a] = seq[a:]; aug[sl - a:] = seq[-1]\n    return aug\n\ndef mirror_hands(seq):\n    aug = seq.copy()\n    lh, rh = aug[:, LH_START:LH_END].copy(), aug[:, RH_START:RH_END].copy()\n    aug[:, LH_START:LH_END] = rh; aug[:, RH_START:RH_END] = lh\n    return aug\n\ndef speed_variation(seq, factor_range=(0.85, 1.15), rng=None):\n    rng = rng or np.random.default_rng()\n    sl = len(seq); factor = rng.uniform(*factor_range)\n    new_len = max(int(sl * factor), 2)\n    orig_idx = np.linspace(0, sl - 1, new_len)\n    tgt_idx = np.linspace(0, new_len - 1, sl)\n    mapped = np.interp(tgt_idx, np.arange(new_len), orig_idx)\n    aug = np.zeros_like(seq)\n    for i in range(seq.shape[1]):\n        aug[:, i] = np.interp(mapped, np.arange(sl), seq[:, i])\n    return aug\n\ndef frame_dropout(seq, drop_rate=0.1, rng=None):\n    rng = rng or np.random.default_rng()\n    aug = seq.copy()\n    for i in range(1, len(aug) - 1):\n        if rng.random() < drop_rate: aug[i] = aug[i - 1]\n    return aug\n\ndef augment_sequence(seq, rng=None):\n    rng = rng or np.random.default_rng()\n    aug = seq.copy()\n    if rng.random() < 0.8: aug = add_gaussian_noise(aug, std=rng.uniform(0.002, 0.008), rng=rng)\n    if rng.random() < 0.5: aug = temporal_shift(aug, max_shift=3, rng=rng)\n    if rng.random() < 0.4: aug = speed_variation(aug, rng=rng)\n    if rng.random() < 0.3: aug = frame_dropout(aug, drop_rate=0.1, rng=rng)\n    return aug\n\n# --- Apply augmentation ---\nif AUGMENT_MULTIPLIER > 0:\n    rng = np.random.default_rng(42)\n    original_count = len(X_train)\n    all_X, all_y = [X_train], [y_train]\n\n    for i in range(AUGMENT_MULTIPLIER):\n        batch = np.array([augment_sequence(s, rng=rng) for s in X_train])\n        all_X.append(batch); all_y.append(y_train)\n\n    if USE_MIRROR:\n        combined_X = np.concatenate(all_X, axis=0)\n        combined_y = np.concatenate(all_y, axis=0)\n        mirrored = np.array([mirror_hands(s) for s in combined_X])\n        all_X = [combined_X, mirrored]; all_y = [combined_y, combined_y]\n\n    X_train = np.concatenate(all_X, axis=0)\n    y_train = np.concatenate(all_y, axis=0)\n\n    idx = rng.permutation(len(X_train))\n    X_train, y_train = X_train[idx], y_train[idx]\n\n    print(f'Augmented: {original_count} -> {len(X_train)} training samples ({len(X_train)/original_count:.1f}x)')\nelse:\n    print('Augmentation disabled (AUGMENT_MULTIPLIER=0)')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 6: Build Bidirectional LSTM Model\nfrom tensorflow.keras.layers import Bidirectional\nfrom tensorflow.keras.regularizers import l2\n\nreg = l2(1e-4)\n\nmodel = Sequential([\n    Bidirectional(LSTM(64, activation='tanh',\n                       kernel_regularizer=reg, recurrent_regularizer=reg),\n                  input_shape=(SEQUENCE_LENGTH, NUM_FEATURES)),\n    BatchNormalization(),\n    Dropout(0.5),\n\n    Dense(32, activation='relu', kernel_regularizer=reg),\n    Dropout(0.4),\n    Dense(len(ACTIONS), activation='softmax')\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n    loss='categorical_crossentropy',\n    metrics=['categorical_accuracy']\n)\nmodel.summary()",
   "metadata": {
    "id": "cell-6-model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 7: Train\nearly_stop = EarlyStopping(\n    monitor='val_categorical_accuracy',\n    patience=50,\n    restore_best_weights=True,\n    verbose=1\n)\ncheckpoint = ModelCheckpoint(\n    'best_model.h5',\n    monitor='val_categorical_accuracy',\n    save_best_only=True,\n    verbose=1\n)\ntb_callback = TensorBoard(log_dir='./logs')\n\nhistory = model.fit(\n    X_train, y_train,\n    epochs=500,\n    batch_size=16,\n    validation_data=(X_val, y_val),\n    callbacks=[early_stop, checkpoint, tb_callback],\n    verbose=1\n)\n\nprint(f'\\nBest validation accuracy: {max(history.history[\"val_categorical_accuracy\"]):.4f}')",
   "metadata": {
    "id": "cell-7-train"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 8: Evaluate on TEST set\nfrom tensorflow.keras.models import load_model\n\n# Load the best model from checkpoint\nbest_model = load_model('best_model.h5')\n\n# Evaluate on X_test (NOT X_train)\ntest_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\nprint(f'Test Loss:     {test_loss:.4f}')\nprint(f'Test Accuracy: {test_acc:.4f}')\n\n# Classification report\ny_pred = best_model.predict(X_test, verbose=0)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true_classes = np.argmax(y_test, axis=1)\n\nprint('\\nClassification Report:')\nprint(classification_report(\n    y_true_classes,\n    y_pred_classes,\n    target_names=ACTIONS.tolist(),\n    zero_division=0\n))\n\n# Confusion matrix heatmap\ncm = confusion_matrix(y_true_classes, y_pred_classes)\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=ACTIONS, yticklabels=ACTIONS)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=150)\nplt.show()\nprint('Confusion matrix saved to confusion_matrix.png')",
   "metadata": {
    "id": "cell-8-evaluate"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 9: Training History Plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history.history['categorical_accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history.history['val_categorical_accuracy'], label='Val Accuracy')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history.history['loss'], label='Train Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()\n",
    "print('Training history saved to training_history.png')"
   ],
   "metadata": {
    "id": "cell-9-history"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 10: Save + Convert to TFLite + Download\nMODEL_PATH = os.path.join(MODELS_DIR, 'action_model.h5')\nbest_model.save(MODEL_PATH)\nnp.save('actions.npy', ACTIONS)\n\n# Export as SavedModel then convert to TFLite\nbest_model.export('/content/saved_model')\n\nconverter = tf.lite.TFLiteConverter.from_saved_model('/content/saved_model')\nconverter.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS,\n    tf.lite.OpsSet.SELECT_TF_OPS,\n]\nconverter._experimental_lower_tensor_list_ops = False\nconverter.experimental_enable_resource_variables = True\ntflite_model = converter.convert()\n\ntflite_path = os.path.join(MODELS_DIR, 'action_model.tflite')\nwith open(tflite_path, 'wb') as f:\n    f.write(tflite_model)\nprint(f'TFLite model saved: {len(tflite_model)/1024:.1f} KB')\n\n# Download to your PC\nfrom google.colab import files\nfiles.download(MODEL_PATH)\nfiles.download(tflite_path)\nfiles.download('actions.npy')\nfiles.download('confusion_matrix.png')\nprint('Downloads started — place action_model.tflite and actions.npy in ml/models/ locally')",
   "metadata": {
    "id": "cell-10-save"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}