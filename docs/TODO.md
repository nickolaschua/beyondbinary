# Task List — ML Lead

<!-- Ralph picks the first unchecked task each iteration. TDD: write failing test, then implement. -->

- [x] Set up pytest infrastructure: create ml/tests/__init__.py, ml/tests/conftest.py with mock MediaPipe results fixture, and a smoke test in ml/tests/test_smoke.py that imports utils and verifies ACTIONS has 10 items and extract_keypoints returns shape (1662,). Run pytest to confirm green.
- [x] Test extract_keypoints edge cases: write ml/tests/test_extract_keypoints.py with tests for (a) all landmarks present → correct shape and non-zero values in all sections, (b) no landmarks detected → shape (1662,) all zeros, (c) only hands detected → pose/face sections are zeros, hand sections are non-zero. Use mock MediaPipe results from conftest.
- [x] Test and fix decode_frame: write ml/tests/test_decode_frame.py testing (a) valid base64 JPEG returns numpy array with 3 channels, (b) base64 with data URL prefix "data:image/jpeg;base64,..." works, (c) empty string raises or returns None, (d) invalid base64 raises or returns None. Then add input validation to ws_server.decode_frame so it returns None instead of crashing on bad input.
- [x] Test and fix load_data: write ml/tests/test_load_data.py using tmp_path fixture to create fake MP_Data directories. Test (a) valid data loads correctly, (b) missing action directory logs warning and continues, (c) missing frame .npy in a sequence skips that sequence, (d) .npy with wrong shape skips that sequence. Verify load_data handles all cases without crashing.
- [x] Deduplicate constants: write ml/tests/test_constants.py that imports ACTIONS from utils.py and from train_model.py and verify_data.py, asserting they are identical. Then refactor train_model.py and verify_data.py to import ACTIONS, NUM_SEQUENCES, SEQUENCE_LENGTH from utils instead of redefining them. Verify all tests still pass.
- [ ] Extract stability filter: write ml/tests/test_stability_filter.py testing a StabilityFilter class with (a) N consecutive identical predictions above threshold → is_stable=True, (b) mixed predictions → is_stable=False, (c) predictions below threshold → reset/not stable. Then create StabilityFilter in utils.py and update ws_server.py and test_realtime.py to use it.
- [ ] Test and fix model loading: write ml/tests/test_ws_server.py testing (a) /health returns status "ok" with model_loaded=False when no model is loaded, (b) /health returns correct actions list. Then fix ws_server.py so it handles a missing model file gracefully at startup (log error, set model=None) instead of crashing. Use fastapi.testclient.TestClient for tests.
- [ ] ALL_TASKS_COMPLETE
