{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Cell 1: Mount Google Drive + Extract Data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!cp /content/drive/MyDrive/MP_Data.zip /content/\n",
    "!unzip -q /content/MP_Data.zip -d /content/\n",
    "!ls /content/MP_Data/"
   ],
   "metadata": {
    "id": "cell-1-mount-drive",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 2: Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "id": "cell-2-imports"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 3: Configuration\n",
    "DATA_PATH = '/content/MP_Data'\n",
    "ACTIONS = np.array([\n",
    "    'Hello', 'Thank_You', 'Help', 'Yes', 'No',\n",
    "    'Please', 'Sorry', 'I_Love_You', 'Stop', 'More'\n",
    "])\n",
    "NUM_SEQUENCES = 30\n",
    "SEQUENCE_LENGTH = 30\n",
    "label_map = {label: num for num, label in enumerate(ACTIONS)}\n",
    "\n",
    "print(f'Actions ({len(ACTIONS)}): {list(ACTIONS)}')\n",
    "print(f'Sequences per action: {NUM_SEQUENCES}')\n",
    "print(f'Frames per sequence: {SEQUENCE_LENGTH}')\n",
    "print(f'Expected total sequences: {len(ACTIONS) * NUM_SEQUENCES}')"
   ],
   "metadata": {
    "id": "cell-3-config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 4: Load and Prepare Data\n",
    "sequences = []\n",
    "labels = []\n",
    "skipped = 0\n",
    "\n",
    "for action in ACTIONS:\n",
    "    for seq_idx in range(NUM_SEQUENCES):\n",
    "        window = []\n",
    "        valid = True\n",
    "        for frame_idx in range(SEQUENCE_LENGTH):\n",
    "            frame_path = os.path.join(DATA_PATH, action, str(seq_idx), f'{frame_idx}.npy')\n",
    "            if not os.path.isfile(frame_path):\n",
    "                valid = False\n",
    "                break\n",
    "            try:\n",
    "                frame = np.load(frame_path)\n",
    "                window.append(frame)\n",
    "            except Exception as e:\n",
    "                print(f'Error loading {frame_path}: {e}')\n",
    "                valid = False\n",
    "                break\n",
    "\n",
    "        if valid and len(window) == SEQUENCE_LENGTH:\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "        else:\n",
    "            skipped += 1\n",
    "\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(np.array(labels), num_classes=len(ACTIONS))\n",
    "\n",
    "print(f'X shape: {X.shape}')  # Expected: (300, 30, 1662)\n",
    "print(f'y shape: {y.shape}')  # Expected: (300, 10)\n",
    "print(f'Skipped sequences: {skipped}')\n",
    "\n",
    "# Per-class counts\n",
    "y_int = np.argmax(y, axis=1)\n",
    "for i, action in enumerate(ACTIONS):\n",
    "    print(f'  {action}: {np.sum(y_int == i)} sequences')"
   ],
   "metadata": {
    "id": "cell-4-load-data"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 5: Train/Test Split (90/10 with stratification)\n",
    "y_integers = np.argmax(y, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y_integers\n",
    ")\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]}')\n",
    "print(f'Test samples:     {X_test.shape[0]}')\n",
    "print(f'Train shape: {X_train.shape}')\n",
    "print(f'Test shape:  {X_test.shape}')"
   ],
   "metadata": {
    "id": "cell-5-split"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 6: Build LSTM Model\n",
    "# CRITICAL: Do not change this architecture\n",
    "# - LSTM activation MUST be 'tanh' (not relu)\n",
    "# - BatchNormalization after each LSTM layer\n",
    "# - Dropout(0.2) for regularization\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, activation='tanh', input_shape=(30, 1662)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    LSTM(128, return_sequences=True, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    LSTM(64, return_sequences=False, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(ACTIONS), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "model.summary()"
   ],
   "metadata": {
    "id": "cell-6-model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 7: Train\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_categorical_accuracy',\n",
    "    patience=30,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_categorical_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "tb_callback = TensorBoard(log_dir='./logs')\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    validation_split=0.15,\n",
    "    callbacks=[early_stop, checkpoint, tb_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f'\\nBest validation accuracy: {max(history.history[\"val_categorical_accuracy\"]):.4f}')"
   ],
   "metadata": {
    "id": "cell-7-train"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 8: Evaluate on TEST set\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the best model from checkpoint\n",
    "best_model = load_model('best_model.h5')\n",
    "\n",
    "# Evaluate on X_test (NOT X_train)\n",
    "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss:     {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Classification report\n",
    "y_pred = best_model.predict(X_test, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(\n",
    "    y_true_classes,\n",
    "    y_pred_classes,\n",
    "    target_names=ACTIONS.tolist(),\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=ACTIONS, yticklabels=ACTIONS)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150)\n",
    "plt.show()\n",
    "print('Confusion matrix saved to confusion_matrix.png')"
   ],
   "metadata": {
    "id": "cell-8-evaluate"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 9: Training History Plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history.history['categorical_accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history.history['val_categorical_accuracy'], label='Val Accuracy')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history.history['loss'], label='Train Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()\n",
    "print('Training history saved to training_history.png')"
   ],
   "metadata": {
    "id": "cell-9-history"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 10: Save and Download\n",
    "model.save('action_model.h5')\n",
    "model.save('action_model_savedmodel')\n",
    "np.save('actions.npy', ACTIONS)\n",
    "\n",
    "print('Saved: action_model.h5')\n",
    "print('Saved: action_model_savedmodel/')\n",
    "print('Saved: actions.npy')\n",
    "\n",
    "# Copy to Google Drive\n",
    "!cp action_model.h5 /content/drive/MyDrive/\n",
    "!cp actions.npy /content/drive/MyDrive/\n",
    "!cp confusion_matrix.png /content/drive/MyDrive/\n",
    "print('Copied to Google Drive')\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('action_model.h5')\n",
    "files.download('actions.npy')\n",
    "files.download('confusion_matrix.png')\n",
    "print('Downloads started')"
   ],
   "metadata": {
    "id": "cell-10-save"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
